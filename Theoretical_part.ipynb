{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#0 Can you come up out 3 sceneraies which use AI methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. How do we use Github; Why do we use Jupyter and Pycharm;\n",
    "#Github: TO create our own repositories and share with others\n",
    "#Juptyter Notebook is better for presentation\n",
    "#Pycharm is better for doing the large project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2. What's the Probability Model?\n",
    "#Probability Model is the random variable and it's ditribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Can you came up with some sceneraies at which we could use Probability Model?\n",
    "# gambling; study traffic patterns of vehicles approaching a particular corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `match` not found.\n"
     ]
    }
   ],
   "source": [
    "#4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?\n",
    "# Usually, we don't know the real distribution of the random variables so we use frequency to approximate to the probability\n",
    "# Regular expression is the most difficult part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5. What's the Language Model;\n",
    "# A statistical language model is a probability distribution over sequences of words. Given such a sequence, say of length m, it assigns a probability to the whole sequence. The language model provides context to \n",
    "#distinguish between words and phrases that sound similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#6. Can you came up with some sceneraies at which we could use Language Model?\n",
    "# To get the style of a writer; To design a smart customer service; \n",
    "#To design the non-player characters in a computer game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#7. What's the 1-gram language model?\n",
    "#P(wk/w1,w2,w3,...,wk-1) = p(wk)\n",
    "#p(w1,w2,w3,...,wT) = p(w1)*p(w2)*p*(w3)...p(wT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. What's the disadvantages and advantages of 1-gram language model;\n",
    "# disadvantages: there is no relationship with the previous information in 1-gram so that the model will not be that exact.\n",
    "# advantages: 1-gram language model will have less training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#9 What's the 2-gram language model?\n",
    "# P(wk/w1,w2,w3,...,wk-1) = p(wk/wk-1)\n",
    "#p(w1,w2,w3,...,wT) = p(w1)*p(w2/w1)*p*(w3/w2)...p(wT/wT-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
