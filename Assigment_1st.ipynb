{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Assigment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "representative = '''\n",
    "representative = 问候 自报 问询 业务相关 结语\n",
    "问候 = 称谓 打招呼 | 打招呼 |问候\n",
    "称谓 = 小哥哥 | 小姐姐 | 大叔 | 大姐姐 | 称谓 老哥\n",
    "打招呼 = 你好鸭！| 您好 ，\n",
    "自报 = 我是您的专属 职位 数字 号 ，\n",
    "数字 = 单个数字 | 数字 单个数字\n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "职位 = 金牌咨询师 | 银牌咨询师 | 职位 金牌咨询师\n",
    "问询 = 请问你需要了解 | 请问您需要了解\n",
    "业务相关 = 健康保险 | 人寿保险 | 意外保险 | 交通保险 | 财产保险 \n",
    "结语 = 吗？\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "customer = '''\n",
    "customer = 自己 目的 选择 \n",
    "自己 = 我 | 在下 | 鄙人 | 朕\n",
    "目的 = 想要咨询一下\n",
    "选择 = 健康保险 | 人寿保险 | 意外保险 | 交通保险 | 财产保险. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "choice = random.choice\n",
    "def generate(gram, target):\n",
    "    if target not in gram: return target #means target is a terminal expression\n",
    "    expaned = [generate(gram, t) for t in choice(gram[target])]\n",
    "    return ''.join([e if e != '/n' else '\\n' for e in expaned if e != 'null'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_grammar(grammar_str, split='=',line_split='\\n'):\n",
    "    grammar = {}\n",
    "    for line in grammar_str.split(line_split):\n",
    "        if not line.strip(): continue\n",
    "        exp, stmt = line.split(split)\n",
    "        grammar[exp.strip()] = [s.split() for s in stmt.split('|')]\n",
    "    return grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "representative_grammar = create_grammar(representative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_n(k):\n",
    "    for i in range(k):\n",
    "      print(generate(gram=representative_grammar,target='representative'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大叔您好，我是您的专属金牌咨询师2286796号，请问您需要了解意外保险吗？\n",
      "大叔您好，我是您的专属银牌咨询师1号，请问你需要了解人寿保险吗？\n",
      "你好鸭！我是您的专属银牌咨询师7号，请问你需要了解人寿保险吗？\n",
      "你好鸭！我是您的专属金牌咨询师4号，请问你需要了解财产保险吗？\n",
      "小哥哥您好，我是您的专属银牌咨询师7号，请问您需要了解财产保险吗？\n",
      "你好鸭！我是您的专属金牌咨询师金牌咨询师4号，请问您需要了解意外保险吗？\n",
      "您好，我是您的专属银牌咨询师金牌咨询师3号，请问你需要了解人寿保险吗？\n",
      "小哥哥老哥你好鸭！我是您的专属银牌咨询师6号，请问你需要了解交通保险吗？\n",
      "你好鸭！我是您的专属金牌咨询师金牌咨询师金牌咨询师39号，请问你需要了解意外保险吗？\n",
      "大叔你好鸭！我是您的专属金牌咨询师金牌咨询师914号，请问您需要了解健康保险吗？\n",
      "小哥哥您好，我是您的专属金牌咨询师3号，请问你需要了解意外保险吗？\n",
      "大叔老哥老哥您好，我是您的专属银牌咨询师761416号，请问你需要了解财产保险吗？\n",
      "小哥哥您好，我是您的专属银牌咨询师17号，请问你需要了解人寿保险吗？\n",
      "小姐姐你好鸭！我是您的专属金牌咨询师5652号，请问您需要了解财产保险吗？\n",
      "大姐姐您好，我是您的专属金牌咨询师9号，请问你需要了解交通保险吗？\n",
      "你好鸭！我是您的专属银牌咨询师金牌咨询师8号，请问你需要了解交通保险吗？\n",
      "小姐姐老哥你好鸭！我是您的专属银牌咨询师金牌咨询师154号，请问您需要了解意外保险吗？\n",
      "您好，我是您的专属金牌咨询师2号，请问您需要了解意外保险吗？\n",
      "小姐姐你好鸭！我是您的专属银牌咨询师金牌咨询师5号，请问您需要了解人寿保险吗？\n",
      "大姐姐你好鸭！我是您的专属银牌咨询师4号，请问你需要了解意外保险吗？\n"
     ]
    }
   ],
   "source": [
    "generate_n(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'按照我们上文中定义的prob_2函数，我们更换一个文本数据源，获得新的Language Model:\\n下载文本数据集（你可以在以下数据集中任选一个，也可以两个都使用）\\n可选数据集1，保险行业问询对话集： https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\\n可选数据集2：豆瓣评论数据集：https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\\n修改代码，获得新的2-gram语言模型\\n进行文本清洗，获得所有的纯文本\\n将这些文本进行切词\\n送入之前定义的语言模型中，判断文本的合理程度'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Assigment 2\n",
    "'''按照我们上文中定义的prob_2函数，我们更换一个文本数据源，获得新的Language Model:\n",
    "下载文本数据集（你可以在以下数据集中任选一个，也可以两个都使用）\n",
    "可选数据集1，保险行业问询对话集： https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\n",
    "可选数据集2：豆瓣评论数据集：https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\n",
    "修改代码，获得新的2-gram语言模型\n",
    "进行文本清洗，获得所有的纯文本\n",
    "将这些文本进行切词\n",
    "送入之前定义的语言模型中，判断文本的合理程度'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat1 = pd.read_table('/Users/jingweili/Documents/人工智能培训/NLP/dat1.txt',sep= '\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "uncn = re.compile(r'[\\u4e00-\\u9fa5]')  ##提取所有的中文字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat = dat1[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def token(string):\n",
    "    return re.findall(uncn,string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_clean = [''.join(token(str(a)))for a in dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('dat_9k.txt', 'w') as f:\n",
    "    for a in dat_clean:\n",
    "        f.write(a + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cut(string): return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/jl/jn6pv0d971ncbntyny0ls13m0000gn/T/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.724 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "TOKEN = []\n",
    "for i, line in enumerate((open('dat_9k.txt'))):\n",
    "    if i % 100 == 0: print(i)\n",
    "    \n",
    "    # replace 10000 with a big number when you do your homework. \n",
    "    \n",
    "    if i > 10000: break    \n",
    "    TOKEN += cut(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_count = Counter(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_1(word):\n",
    "    return words_count[word] / len(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TOKEN_2_GRAM = [''.join(TOKEN[i:i+2]) for i in range(len(TOKEN[:-2]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_count_2 = Counter(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_2(word1, word2):\n",
    "    if word1 + word2 in words_count_2: return words_count_2[word1+word2] / len(TOKEN_2_GRAM)\n",
    "    else:\n",
    "        return 1 / len(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.873901854645488e-05"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2('法律','要求')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4789836424409147e-05"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2('我们','吃饭')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###3\n",
    "#当我们能够生成随机的语言并且能判断之后，我们就可以生成更加合理的语言了。请定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成n个句子，并能选择一个最合理的句子:\n",
    "#提示，要实现这个函数，你需要Python的sorted函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_probablity(sentence):\n",
    "    words = cut(sentence)\n",
    "    \n",
    "    sentence_pro = 1\n",
    "    \n",
    "    for i, word in enumerate(words[:-1]):\n",
    "        next_ = words[i+1]\n",
    "        \n",
    "        probability = prob_2(word, next_)\n",
    "        \n",
    "        sentence_pro *= probability\n",
    "    \n",
    "    return sentence_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2 = []\n",
    "def generate_best(k): # k is the number of the sentences you want to generate\n",
    "    for sen in [generate(gram=representative_grammar, target='representative') for i in range(k)]:\n",
    "       global sent2\n",
    "       sent2 += [(sen,get_probablity(sen))]\n",
    "    sn = sorted(sent2, key=lambda x: x[1]) #sorting the k sentences by the probablity\n",
    "    #print(sn) ##you can print sn here to check whether the sentence we get has the biggest probability\n",
    "    print('sentence: {} is more possible'.format(sn[-1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: 您好，我是您的专属金牌咨询师5号，请问你需要了解健康保险吗？ is more possible\n"
     ]
    }
   ],
   "source": [
    "generate_best(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
